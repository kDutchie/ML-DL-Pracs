{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144519\n",
      "Total Vocab:  45\n",
      "Total Patterns:  144419\n",
      "Epoch 1/5\n",
      "144419/144419 [==============================] - 991s 7ms/step - loss: 2.9564\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.95638, saving model to C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-01-2.9564.hdf5\n",
      "Epoch 2/5\n",
      "144419/144419 [==============================] - 1053s 7ms/step - loss: 2.7553\n",
      "\n",
      "Epoch 00002: loss improved from 2.95638 to 2.75532, saving model to C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-02-2.7553.hdf5\n",
      "Epoch 3/5\n",
      "144419/144419 [==============================] - 921s 6ms/step - loss: 2.6529\n",
      "\n",
      "Epoch 00003: loss improved from 2.75532 to 2.65288, saving model to C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-03-2.6529.hdf5\n",
      "Epoch 4/5\n",
      "144419/144419 [==============================] - 624s 4ms/step - loss: 2.5702\n",
      "\n",
      "Epoch 00004: loss improved from 2.65288 to 2.57020, saving model to C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-04-2.5702.hdf5\n",
      "Epoch 5/5\n",
      "144419/144419 [==============================] - 640s 4ms/step - loss: 2.5011\n",
      "\n",
      "Epoch 00005: loss improved from 2.57020 to 2.50113, saving model to C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-05-2.5011.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21eae079d48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "# load ascii text and covert to lowercase\n",
    "filename = r\"C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=r\"C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=5, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ho is to give the prizes?' quite a chorus of voices asked.\n",
      "\n",
      "'why, she, of course,' said the dodo, po \"\n",
      " the woele to the toeee  \n",
      "\n",
      "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "filename = r\"C:\\Users\\kshitij\\Desktop\\MyDesk\\Apps\\weights-improvement-05-2.5011.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
